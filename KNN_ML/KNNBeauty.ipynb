{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# These are all the imports needed for the assignment\n",
    "%matplotlib inline\n",
    "\n",
    "# Import nltk package (Natural Language Toolkit)\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\19495\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\19495\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the NLTK English tokenizer and the stopwords of all languages\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal_Care_Appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', \\\n",
    "           'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date']\n",
    "elec_df = pd.read_csv(\"C:/Users/19495/DS3ProjectFiles/amazon_reviews_us_Beauty_v1_00.tsv.gz\", names =  columns, sep = '\\t').iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_df = elec_df.sample(n = 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_file = elec_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sampling(df):\n",
    "    # Since we know that there are more unverified than verified --> we sample based on that\n",
    "    \n",
    "    # Since there are no data values in 'verified_purchase' columns that deviate from 'Y' or 'N' we proceed\n",
    "    verified_count_df = df[df['verified_purchase'] == 'Y']\n",
    "    unverified_count_df = df[df['verified_purchase'] == 'N']\n",
    "    \n",
    "    print(\"Number of verified purchases:\", len(verified_count_df))\n",
    "    print(\"Number of unverified purchases:\", len(unverified_count_df))\n",
    "    \n",
    "    sample_len = len(unverified_count_df)\n",
    "    \n",
    "    verified_sample_df = verified_count_df.sample(n = sample_len)\n",
    "    unified_df = pd.concat([unverified_count_df, verified_sample_df])\n",
    "    \n",
    "    print(\"Number of verified purchases (balanced dataset):\", len(unified_df[unified_df['verified_purchase'] == 'Y']))\n",
    "    print(\"Number of unverified purchases (balanced dataset):\", len(unified_df[unified_df['verified_purchase'] == 'N']))\n",
    "    \n",
    "    return unified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of verified purchases: 826615\n",
      "Number of unverified purchases: 173377\n",
      "Number of verified purchases (balanced dataset): 173377\n",
      "Number of unverified purchases (balanced dataset): 173377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2392747</th>\n",
       "      <td>US</td>\n",
       "      <td>11863580</td>\n",
       "      <td>R1JQNN06UHOWMF</td>\n",
       "      <td>B00DVMYZX2</td>\n",
       "      <td>367142670</td>\n",
       "      <td>White Beeswax Bees Wax Pastilles Beads Premium Prime Grade A 100% Pure 16 oz, 1 LB</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>thanks</td>\n",
       "      <td>2014-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892320</th>\n",
       "      <td>US</td>\n",
       "      <td>41247587</td>\n",
       "      <td>R288YNF5VNK6CC</td>\n",
       "      <td>B005X2F7JY</td>\n",
       "      <td>367161615</td>\n",
       "      <td>SHANY Cosmetics Nail Lquer Set</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>I love the nail polishes they are so pretty and affordable</td>\n",
       "      <td>2014-12-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        marketplace customer_id       review_id  product_id product_parent  \\\n",
       "2392747          US    11863580  R1JQNN06UHOWMF  B00DVMYZX2      367142670   \n",
       "1892320          US    41247587  R288YNF5VNK6CC  B005X2F7JY      367161615   \n",
       "\n",
       "                                                                              product_title  \\\n",
       "2392747  White Beeswax Bees Wax Pastilles Beads Premium Prime Grade A 100% Pure 16 oz, 1 LB   \n",
       "1892320                                                      SHANY Cosmetics Nail Lquer Set   \n",
       "\n",
       "        product_category star_rating helpful_votes total_votes vine  \\\n",
       "2392747           Beauty           5             0           0    N   \n",
       "1892320           Beauty           5             0           0    N   \n",
       "\n",
       "        verified_purchase review_headline  \\\n",
       "2392747                 N      Five Stars   \n",
       "1892320                 N      Five Stars   \n",
       "\n",
       "                                                        review_body  \\\n",
       "2392747                                                      thanks   \n",
       "1892320  I love the nail polishes they are so pretty and affordable   \n",
       "\n",
       "        review_date  \n",
       "2392747  2014-09-17  \n",
       "1892320  2014-12-17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balanced_elec = df_sampling(one_file)\n",
    "display(balanced_elec.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Beauty sample will have size: (346754, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"The Beauty sample will have size:\", balanced_elec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_file = balanced_elec.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of verified purchases (balanced dataset): 826615\n",
      "Number of unverified purchases (balanced dataset): 173377\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of verified purchases (balanced dataset):\", len(one_file[one_file['verified_purchase'] == 'Y']))\n",
    "print(\"Number of unverified purchases (balanced dataset):\", len(one_file[one_file['verified_purchase'] == 'N']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5             509320\n",
       "5             126601\n",
       "4             118715\n",
       "1              73092\n",
       "3              63766\n",
       "2              42572\n",
       "4              26128\n",
       "1              16320\n",
       "3              14113\n",
       "2               9365\n",
       "2015-06-02         1\n",
       "2015-03-18         1\n",
       "2015-08-16         1\n",
       "2014-10-09         1\n",
       "2015-03-31         1\n",
       "2015-04-09         1\n",
       "2015-04-14         1\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Star rating of the format '2015-04-02' exists! In addition, np.nan exists in the helpful and total votes\n",
    "one_file['star_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the type of relevant columns to int\n",
    "one_file['star_rating'] = (one_file['star_rating']).apply(lambda star: np.NaN if (len(str(star)) > 3) else star)\n",
    "one_file['star_rating'] = one_file['star_rating'].apply(lambda star: star if (pd.isna(star)) else int(star))\n",
    "one_file['helpful_votes'] = one_file['helpful_votes'].apply(lambda vote: vote if (pd.isna(vote)) else int(vote))\n",
    "one_file['total_votes'] = one_file['total_votes'].apply(lambda vote: vote if (pd.isna(vote)) else int(int(vote)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\19495\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\19495\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cleaning(df, col):\n",
    "    # Drop rows with na values\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    new_col_name = 'new_' + col\n",
    "    \n",
    "    df[new_col_name] = df[col].copy() \n",
    "    \n",
    "    # Remove unwanted formatting characters\n",
    "    format_strs = dict.fromkeys(['<br /><br />', '&#34', 'br', '&quot', '<br />'], ' ')\n",
    "    \n",
    "    for key in format_strs:\n",
    "        df[new_col_name] = df[new_col_name].apply(lambda review: review.replace(key, format_strs[key]))\n",
    "    # removing quotes produces smthg like this --> 'The product has great ;sound; --> we must remove punctuation\n",
    "\n",
    "    \n",
    "    # Case normalization (lower case)\n",
    "    df[new_col_name] = df[new_col_name].str.lower()\n",
    "    \n",
    "    remove_dict = {\"0\": \"\", \"1\": \"\", \"2\": \"\", \"3\": \"\", \"4\": \"\", \"5\": \"\", \"6\": \"\", \"7\": \"\", \"8\": \"\", \"9\": \"\",\n",
    "                   \"(\": \"\", \")\":\"\"}\n",
    "    for key, val in remove_dict.items():\n",
    "        df[new_col_name] = df[new_col_name].apply(\n",
    "            lambda x: x.replace(key, val))\n",
    "        \n",
    "    # Remove stopwords\n",
    "    stop_lst = stopwords.words('english')\n",
    "    #stop_lst += ([\"can't\", \"i'm\" \"i'd\", \"i've\", \"i'll\", \"that's\", \"there's\", \"they're\"])\n",
    "    # ****Do we not have to take stopwords out BEFORE removing punctuation? Otherwise words with punct like “cant” remains there\n",
    "    df[new_col_name] = df[new_col_name].apply(lambda text_body: \" \".join([word for word in text_body.split() if word not in (stop_lst)]))\n",
    "    \n",
    "    # Removing Unicode Chars (punctuation, URL, @)\n",
    "    df[new_col_name] = df[new_col_name].apply(lambda rev: re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", rev))\n",
    "    \n",
    "    # Lemmatization\n",
    "    word_lemmatizer = WordNetLemmatizer()\n",
    "    df[new_col_name] = df[new_col_name].apply(lambda txt: \" \".join([(word_lemmatizer.lemmatize(word)) for word in txt.split()]))\n",
    "    \n",
    "    # Convert the type of relevant columns to int\n",
    "    df['star_rating'] = (df['star_rating']).apply(lambda star: np.NaN if (len(str(star)) > 3) else star)\n",
    "    df['star_rating'] = df['star_rating'].apply(lambda star: star if (pd.isna(star)) else int(star))\n",
    "    df['helpful_votes'] = df['helpful_votes'].apply(lambda vote: vote if (pd.isna(vote)) else int(vote))\n",
    "    df['total_votes'] = df['total_votes'].apply(lambda vote: vote if (pd.isna(vote)) else int(int(vote)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>new_review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2392747</th>\n",
       "      <td>thanks</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892320</th>\n",
       "      <td>I love the nail polishes they are so pretty and affordable</td>\n",
       "      <td>love nail polish pretty affordable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825907</th>\n",
       "      <td>This diffuser is AWESOME! It has worked perfectly. Would definitely recommend.</td>\n",
       "      <td>diffuser awesome worked perfectly would definitely recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552940</th>\n",
       "      <td>I was over enthusiastic about using it and rubed too hard on my skin. Ouch. And it took forever to remove my thick dark sexy leg hairs :-)</td>\n",
       "      <td>enthusiastic using rubed hard skin ouch took forever remove thick dark sexy leg hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543972</th>\n",
       "      <td>When I placed my order, I was a little anxious bc of all the good reviews and research I've done...i couldn't wait to use it and see the results...when I got the night cream and foam wash within a week I was very impress and gave 5 star rating to my seller...right away that night, I used it and kept my fingers crossed BC im tired of looking for products to help the crazy and over productive worst case of dark spots all over my oily young Asian acne skin..when I got up the next morning, for the first time, my boyfriend said\\\\\" your skin is so soft\\\\\"... I Ran to the bathroom and no breakouts..but surprisingly the dark spots got one shade lighter..at this point my smile is from ear to ear..I know everybody is different and products work differently for everybody but I wanted to share this review BC It works for me and it may not work for the next person but don't feel discourage cause there is something out there for you..just keep looking and wear a lot of sun screen</td>\n",
       "      <td>placed order little anxious bc good review research ive donei wait use see resultswhen got night cream foam wash within week impress gave star rating sellerright away night used kept finger crossed bc im tired looking product help crazy productive worst case dark spot oily young asian acne skinwhen got next morning first time boyfriend said skin soft ran bathroom eakoutsbut surprisingly dark spot got one shade lighterat point smile ear eari know everybody different product work differently everybody wanted share review bc work may work next person feel discourage cause something youjust keep looking wear lot sun screen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  review_body  \\\n",
       "2392747                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                thanks   \n",
       "1892320                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I love the nail polishes they are so pretty and affordable   \n",
       "1825907                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This diffuser is AWESOME! It has worked perfectly. Would definitely recommend.   \n",
       "552940                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             I was over enthusiastic about using it and rubed too hard on my skin. Ouch. And it took forever to remove my thick dark sexy leg hairs :-)   \n",
       "4543972  When I placed my order, I was a little anxious bc of all the good reviews and research I've done...i couldn't wait to use it and see the results...when I got the night cream and foam wash within a week I was very impress and gave 5 star rating to my seller...right away that night, I used it and kept my fingers crossed BC im tired of looking for products to help the crazy and over productive worst case of dark spots all over my oily young Asian acne skin..when I got up the next morning, for the first time, my boyfriend said\\\\\" your skin is so soft\\\\\"... I Ran to the bathroom and no breakouts..but surprisingly the dark spots got one shade lighter..at this point my smile is from ear to ear..I know everybody is different and products work differently for everybody but I wanted to share this review BC It works for me and it may not work for the next person but don't feel discourage cause there is something out there for you..just keep looking and wear a lot of sun screen   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            new_review_body  \n",
       "2392747                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              thanks  \n",
       "1892320                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  love nail polish pretty affordable  \n",
       "1825907                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        diffuser awesome worked perfectly would definitely recommend  \n",
       "552940                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 enthusiastic using rubed hard skin ouch took forever remove thick dark sexy leg hair  \n",
       "4543972  placed order little anxious bc good review research ive donei wait use see resultswhen got night cream foam wash within week impress gave star rating sellerright away night used kept finger crossed bc im tired looking product help crazy productive worst case dark spot oily young asian acne skinwhen got next morning first time boyfriend said skin soft ran bathroom eakoutsbut surprisingly dark spot got one shade lighterat point smile ear eari know everybody different product work differently everybody wanted share review bc work may work next person feel discourage cause something youjust keep looking wear lot sun screen  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned2 = df_cleaning(one_file, 'review_body')\n",
    "cleaned2.get(['review_body', 'new_review_body']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>new_review_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2392747</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>five star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892320</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>five star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825907</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>five star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552940</th>\n",
       "      <td>I was over enthusiastic about using it and rubed too ...</td>\n",
       "      <td>enthusiastic using rubed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543972</th>\n",
       "      <td>impress</td>\n",
       "      <td>impress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review_headline  \\\n",
       "2392747                                                Five Stars   \n",
       "1892320                                                Five Stars   \n",
       "1825907                                                Five Stars   \n",
       "552940   I was over enthusiastic about using it and rubed too ...   \n",
       "4543972                                                   impress   \n",
       "\n",
       "              new_review_headline  \n",
       "2392747                 five star  \n",
       "1892320                 five star  \n",
       "1825907                 five star  \n",
       "552940   enthusiastic using rubed  \n",
       "4543972                   impress  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned2 = df_cleaning(one_file, 'review_headline')\n",
    "cleaned2.get(['review_headline', 'new_review_headline']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>new_product_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2392747</th>\n",
       "      <td>White Beeswax Bees Wax Pastilles Beads Premium Prime Grade A 100% Pure 16 oz, 1 LB</td>\n",
       "      <td>white beeswax bee wax pastille bead premium prime grade pure oz lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892320</th>\n",
       "      <td>SHANY Cosmetics Nail Lquer Set</td>\n",
       "      <td>shany cosmetic nail lquer set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825907</th>\n",
       "      <td>ZAQ Noor Multi Color Litemist Aromatherapy Essential Oil Diffuser</td>\n",
       "      <td>zaq noor multi color litemist aromatherapy essential oil diffuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552940</th>\n",
       "      <td>Soften Her - Soften Body Hair, Exfoliate, and Prevent In-grown Hairs</td>\n",
       "      <td>soften soften body hair exfoliate prevent ingrown hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543972</th>\n",
       "      <td>Pond's Flawless White Brightening Night Cream 50 grams</td>\n",
       "      <td>pond flawless white brightening night cream gram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              product_title  \\\n",
       "2392747  White Beeswax Bees Wax Pastilles Beads Premium Prime Grade A 100% Pure 16 oz, 1 LB   \n",
       "1892320                                                      SHANY Cosmetics Nail Lquer Set   \n",
       "1825907                   ZAQ Noor Multi Color Litemist Aromatherapy Essential Oil Diffuser   \n",
       "552940                 Soften Her - Soften Body Hair, Exfoliate, and Prevent In-grown Hairs   \n",
       "4543972                              Pond's Flawless White Brightening Night Cream 50 grams   \n",
       "\n",
       "                                                          new_product_title  \n",
       "2392747  white beeswax bee wax pastille bead premium prime grade pure oz lb  \n",
       "1892320                                       shany cosmetic nail lquer set  \n",
       "1825907   zaq noor multi color litemist aromatherapy essential oil diffuser  \n",
       "552940               soften soften body hair exfoliate prevent ingrown hair  \n",
       "4543972                    pond flawless white brightening night cream gram  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned2 = df_cleaning(one_file, 'product_title')\n",
    "cleaned2.get(['product_title', 'new_product_title']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of verified purchases (balanced dataset): 826526\n",
      "Number of unverified purchases (balanced dataset): 173363\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of verified purchases (balanced dataset):\", len(cleaned2[cleaned2['verified_purchase'] == 'Y']))\n",
    "print(\"Number of unverified purchases (balanced dataset):\", len(cleaned2[cleaned2['verified_purchase'] == 'N']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_scores(review):\n",
    "    \"\"\"\n",
    "    create new dataframe with just the proportions for each review\n",
    "    four columns\n",
    "    neg_prop, pos_prop, neu_prop, compound_prop and will contain these values\n",
    "    obtained from the vator sentiment algorithm\n",
    "    \"\"\"\n",
    "    snt = analyser.polarity_scores(review)\n",
    "    return snt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_file = cleaned2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 4 new columns to cleaned_elec df: neg_prop, neu_prop, pos_prop, compound_prop\n",
    "one_file['rev_dict'] = one_file['new_review_body'].apply(get_sentiment_scores)\n",
    "\n",
    "def get_neg(review_dict):\n",
    "    return review_dict['neg']\n",
    "\n",
    "def get_neu(review_dict):\n",
    "    return review_dict['neu']\n",
    "\n",
    "def get_pos(review_dict):\n",
    "    return review_dict['pos']\n",
    "\n",
    "def get_compound(review_dict):\n",
    "    return review_dict['compound']\n",
    "\n",
    "def only_compound(x):\n",
    "    dct = get_sentiment_scores(x)\n",
    "    return dct['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get neg prop\n",
    "one_file['neg_prop'] = one_file['rev_dict'].apply(get_neg)\n",
    "#get neu prop\n",
    "one_file['neu_prop'] = one_file['rev_dict'].apply(get_neu)\n",
    "#get pos prop\n",
    "one_file['pos_prop'] = one_file['rev_dict'].apply(get_pos)\n",
    "#get compound prop\n",
    "one_file['compound_prop'] = one_file['rev_dict'].apply(get_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_file.to_csv('beauty_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of verified purchases (balanced dataset): 826526\n",
      "Number of unverified purchases (balanced dataset): 173363\n"
     ]
    }
   ],
   "source": [
    "one_file.head()\n",
    "print(\"Number of verified purchases (balanced dataset):\", len(one_file[one_file['verified_purchase'] == 'Y']))\n",
    "print(\"Number of unverified purchases (balanced dataset):\", len(one_file[one_file['verified_purchase'] == 'N']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names,\n",
    "                          fname, epoch,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True, target=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    plt.style.use('default')\n",
    "\n",
    "    # # only true if it weren't normalized:\n",
    "    # accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    # misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm[np.isnan(cm)] = 0.0\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 4))\n",
    "    ax = plt.axes()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    if target == \"rule-based\":\n",
    "        plt.title(title + ' for rule-based PF')\n",
    "    else:\n",
    "        plt.title(title + ' for MLPF at epoch ' + str(epoch))\n",
    "\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlim(-1, len(target_names))\n",
    "    plt.ylim(-1, len(target_names))\n",
    "    plt.xlabel('Predicted label')\n",
    "    # plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname + '.png')\n",
    "    plt.savefig(fname + '.pdf')\n",
    "    #plt.close(fig)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n",
       "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
       "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
       "       'review_headline', 'review_body', 'review_date', 'new_review_body',\n",
       "       'new_review_headline', 'new_product_title', 'rev_dict', 'neg_prop',\n",
       "       'neu_prop', 'pos_prop', 'compound_prop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_file['prod_title_comp'] = one_file.get(\"new_product_title\").apply(only_compound)\n",
    "one_file['rev_title_comp'] = one_file.get(\"new_review_headline\").apply(only_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helpful_prop(df):  \n",
    "    vote_series = pd.Series(df['helpful_votes'] / df['total_votes'])\n",
    "    # !! All nan values in votes_prop should be changed to zero: this means that 0/0 occurred !!\n",
    "    vote_series = vote_series.fillna(0)\n",
    "    return vote_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for id'ing the review body sentiments into -1, 0, 1 depending on majority sentiment\n",
    "def id_for_dictionary(dic):\n",
    "    if len(dic) == 4:\n",
    "        ind = list(dic.values()).index(max(list(dic.values())[0:-1])) #remove the compound\n",
    "    else:\n",
    "        ind = list(dic.values()).index(max(list(dic.values())))\n",
    "    \n",
    "    # If at idx 1, neutral sent\n",
    "    if ind == 1:\n",
    "        return 0\n",
    "    # If at idx 0, negative sent\n",
    "    elif ind == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for id'ing the helper vote proportion\n",
    "def id_for_prop(prop):\n",
    "    if prop < 0.45:\n",
    "        return -1\n",
    "    elif prop > 0.55:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>new_review_body</th>\n",
       "      <th>new_review_headline</th>\n",
       "      <th>new_product_title</th>\n",
       "      <th>rev_dict</th>\n",
       "      <th>neg_prop</th>\n",
       "      <th>neu_prop</th>\n",
       "      <th>pos_prop</th>\n",
       "      <th>compound_prop</th>\n",
       "      <th>prod_title_comp</th>\n",
       "      <th>rev_title_comp</th>\n",
       "      <th>help_prop</th>\n",
       "      <th>rev_bod_id</th>\n",
       "      <th>help_prop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2392747</th>\n",
       "      <td>US</td>\n",
       "      <td>11863580</td>\n",
       "      <td>R1JQNN06UHOWMF</td>\n",
       "      <td>B00DVMYZX2</td>\n",
       "      <td>367142670</td>\n",
       "      <td>White Beeswax Bees Wax Pastilles Beads Premium Prime Grade A 100% Pure 16 oz, 1 LB</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>thanks</td>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>thanks</td>\n",
       "      <td>five star</td>\n",
       "      <td>white beeswax bee wax pastille bead premium prime grade pure oz lb</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4404}</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892320</th>\n",
       "      <td>US</td>\n",
       "      <td>41247587</td>\n",
       "      <td>R288YNF5VNK6CC</td>\n",
       "      <td>B005X2F7JY</td>\n",
       "      <td>367161615</td>\n",
       "      <td>SHANY Cosmetics Nail Lquer Set</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>I love the nail polishes they are so pretty and affordable</td>\n",
       "      <td>2014-12-17</td>\n",
       "      <td>love nail polish pretty affordable</td>\n",
       "      <td>five star</td>\n",
       "      <td>shany cosmetic nail lquer set</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.288, 'pos': 0.712, 'compound': 0.8126}</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825907</th>\n",
       "      <td>US</td>\n",
       "      <td>45633542</td>\n",
       "      <td>R33VSPETWJ8G4U</td>\n",
       "      <td>B008RP6GGC</td>\n",
       "      <td>333805416</td>\n",
       "      <td>ZAQ Noor Multi Color Litemist Aromatherapy Essential Oil Diffuser</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>This diffuser is AWESOME! It has worked perfectly. Would definitely recommend.</td>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>diffuser awesome worked perfectly would definitely recommend</td>\n",
       "      <td>five star</td>\n",
       "      <td>zaq noor multi color litemist aromatherapy essential oil diffuser</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.182, 'pos': 0.818, 'compound': 0.926}</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552940</th>\n",
       "      <td>US</td>\n",
       "      <td>13751569</td>\n",
       "      <td>R1RBR7HLQ83WDH</td>\n",
       "      <td>B00KQTDLGK</td>\n",
       "      <td>750897889</td>\n",
       "      <td>Soften Her - Soften Body Hair, Exfoliate, and Prevent In-grown Hairs</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I was over enthusiastic about using it and rubed too ...</td>\n",
       "      <td>I was over enthusiastic about using it and rubed too hard on my skin. Ouch. And it took forever to remove my thick dark sexy leg hairs :-)</td>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>enthusiastic using rubed hard skin ouch took forever remove thick dark sexy leg hair</td>\n",
       "      <td>enthusiastic using rubed</td>\n",
       "      <td>soften soften body hair exfoliate prevent ingrown hair</td>\n",
       "      <td>{'neg': 0.074, 'neu': 0.579, 'pos': 0.347, 'compound': 0.7351}</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543972</th>\n",
       "      <td>US</td>\n",
       "      <td>23873619</td>\n",
       "      <td>RZPMJ3B8G65NZ</td>\n",
       "      <td>B003OBE530</td>\n",
       "      <td>965340858</td>\n",
       "      <td>Pond's Flawless White Brightening Night Cream 50 grams</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>impress</td>\n",
       "      <td>When I placed my order, I was a little anxious bc of all the good reviews and research I've done...i couldn't wait to use it and see the results...when I got the night cream and foam wash within a week I was very impress and gave 5 star rating to my seller...right away that night, I used it and kept my fingers crossed BC im tired of looking for products to help the crazy and over productive worst case of dark spots all over my oily young Asian acne skin..when I got up the next morning, for the first time, my boyfriend said\\\\\" your skin is so soft\\\\\"... I Ran to the bathroom and no breakouts..but surprisingly the dark spots got one shade lighter..at this point my smile is from ear to ear..I know everybody is different and products work differently for everybody but I wanted to share this review BC It works for me and it may not work for the next person but don't feel discourage cause there is something out there for you..just keep looking and wear a lot of sun screen</td>\n",
       "      <td>2012-06-23</td>\n",
       "      <td>placed order little anxious bc good review research ive donei wait use see resultswhen got night cream foam wash within week impress gave star rating sellerright away night used kept finger crossed bc im tired looking product help crazy productive worst case dark spot oily young asian acne skinwhen got next morning first time boyfriend said skin soft ran bathroom eakoutsbut surprisingly dark spot got one shade lighterat point smile ear eari know everybody different product work differently everybody wanted share review bc work may work next person feel discourage cause something youjust keep looking wear lot sun screen</td>\n",
       "      <td>impress</td>\n",
       "      <td>pond flawless white brightening night cream gram</td>\n",
       "      <td>{'neg': 0.119, 'neu': 0.752, 'pos': 0.129, 'compound': 0.0591}</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        marketplace customer_id       review_id  product_id product_parent  \\\n",
       "2392747          US    11863580  R1JQNN06UHOWMF  B00DVMYZX2      367142670   \n",
       "1892320          US    41247587  R288YNF5VNK6CC  B005X2F7JY      367161615   \n",
       "1825907          US    45633542  R33VSPETWJ8G4U  B008RP6GGC      333805416   \n",
       "552940           US    13751569  R1RBR7HLQ83WDH  B00KQTDLGK      750897889   \n",
       "4543972          US    23873619   RZPMJ3B8G65NZ  B003OBE530      965340858   \n",
       "\n",
       "                                                                              product_title  \\\n",
       "2392747  White Beeswax Bees Wax Pastilles Beads Premium Prime Grade A 100% Pure 16 oz, 1 LB   \n",
       "1892320                                                      SHANY Cosmetics Nail Lquer Set   \n",
       "1825907                   ZAQ Noor Multi Color Litemist Aromatherapy Essential Oil Diffuser   \n",
       "552940                 Soften Her - Soften Body Hair, Exfoliate, and Prevent In-grown Hairs   \n",
       "4543972                              Pond's Flawless White Brightening Night Cream 50 grams   \n",
       "\n",
       "        product_category  star_rating  helpful_votes  total_votes vine  \\\n",
       "2392747           Beauty            5              0            0    N   \n",
       "1892320           Beauty            5              0            0    N   \n",
       "1825907           Beauty            5              0            0    N   \n",
       "552940            Beauty            3              2            2    N   \n",
       "4543972           Beauty            5              7           10    N   \n",
       "\n",
       "        verified_purchase  \\\n",
       "2392747                 N   \n",
       "1892320                 N   \n",
       "1825907                 Y   \n",
       "552940                  Y   \n",
       "4543972                 Y   \n",
       "\n",
       "                                                  review_headline  \\\n",
       "2392747                                                Five Stars   \n",
       "1892320                                                Five Stars   \n",
       "1825907                                                Five Stars   \n",
       "552940   I was over enthusiastic about using it and rubed too ...   \n",
       "4543972                                                   impress   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  review_body  \\\n",
       "2392747                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                thanks   \n",
       "1892320                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I love the nail polishes they are so pretty and affordable   \n",
       "1825907                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This diffuser is AWESOME! It has worked perfectly. Would definitely recommend.   \n",
       "552940                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             I was over enthusiastic about using it and rubed too hard on my skin. Ouch. And it took forever to remove my thick dark sexy leg hairs :-)   \n",
       "4543972  When I placed my order, I was a little anxious bc of all the good reviews and research I've done...i couldn't wait to use it and see the results...when I got the night cream and foam wash within a week I was very impress and gave 5 star rating to my seller...right away that night, I used it and kept my fingers crossed BC im tired of looking for products to help the crazy and over productive worst case of dark spots all over my oily young Asian acne skin..when I got up the next morning, for the first time, my boyfriend said\\\\\" your skin is so soft\\\\\"... I Ran to the bathroom and no breakouts..but surprisingly the dark spots got one shade lighter..at this point my smile is from ear to ear..I know everybody is different and products work differently for everybody but I wanted to share this review BC It works for me and it may not work for the next person but don't feel discourage cause there is something out there for you..just keep looking and wear a lot of sun screen   \n",
       "\n",
       "        review_date  \\\n",
       "2392747  2014-09-17   \n",
       "1892320  2014-12-17   \n",
       "1825907  2014-12-28   \n",
       "552940   2015-06-17   \n",
       "4543972  2012-06-23   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            new_review_body  \\\n",
       "2392747                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              thanks   \n",
       "1892320                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  love nail polish pretty affordable   \n",
       "1825907                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        diffuser awesome worked perfectly would definitely recommend   \n",
       "552940                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 enthusiastic using rubed hard skin ouch took forever remove thick dark sexy leg hair   \n",
       "4543972  placed order little anxious bc good review research ive donei wait use see resultswhen got night cream foam wash within week impress gave star rating sellerright away night used kept finger crossed bc im tired looking product help crazy productive worst case dark spot oily young asian acne skinwhen got next morning first time boyfriend said skin soft ran bathroom eakoutsbut surprisingly dark spot got one shade lighterat point smile ear eari know everybody different product work differently everybody wanted share review bc work may work next person feel discourage cause something youjust keep looking wear lot sun screen   \n",
       "\n",
       "              new_review_headline  \\\n",
       "2392747                 five star   \n",
       "1892320                 five star   \n",
       "1825907                 five star   \n",
       "552940   enthusiastic using rubed   \n",
       "4543972                   impress   \n",
       "\n",
       "                                                          new_product_title  \\\n",
       "2392747  white beeswax bee wax pastille bead premium prime grade pure oz lb   \n",
       "1892320                                       shany cosmetic nail lquer set   \n",
       "1825907   zaq noor multi color litemist aromatherapy essential oil diffuser   \n",
       "552940               soften soften body hair exfoliate prevent ingrown hair   \n",
       "4543972                    pond flawless white brightening night cream gram   \n",
       "\n",
       "                                                               rev_dict  \\\n",
       "2392747        {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4404}   \n",
       "1892320    {'neg': 0.0, 'neu': 0.288, 'pos': 0.712, 'compound': 0.8126}   \n",
       "1825907     {'neg': 0.0, 'neu': 0.182, 'pos': 0.818, 'compound': 0.926}   \n",
       "552940   {'neg': 0.074, 'neu': 0.579, 'pos': 0.347, 'compound': 0.7351}   \n",
       "4543972  {'neg': 0.119, 'neu': 0.752, 'pos': 0.129, 'compound': 0.0591}   \n",
       "\n",
       "         neg_prop  neu_prop  pos_prop  compound_prop  prod_title_comp  \\\n",
       "2392747     0.000     0.000     1.000         0.4404           0.0000   \n",
       "1892320     0.000     0.288     0.712         0.8126           0.0000   \n",
       "1825907     0.000     0.182     0.818         0.9260           0.0000   \n",
       "552940      0.074     0.579     0.347         0.7351           0.0258   \n",
       "4543972     0.119     0.752     0.129         0.0591           0.7783   \n",
       "\n",
       "         rev_title_comp  help_prop  rev_bod_id  help_prop_id  \n",
       "2392747          0.0000        0.0           1            -1  \n",
       "1892320          0.0000        0.0           1            -1  \n",
       "1825907          0.0000        0.0           1            -1  \n",
       "552940           0.4939        1.0           0             1  \n",
       "4543972          0.4404        0.7           0             1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_file['help_prop'] = helpful_prop(one_file)\n",
    "one_file['rev_bod_id'] = one_file['rev_dict'].apply(id_for_dictionary)\n",
    "one_file['help_prop_id'] = one_file[\"help_prop\"].apply(id_for_prop)\n",
    "one_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verified_purchase     object\n",
       "prod_title_comp      float64\n",
       "star_rating            int64\n",
       "rev_title_comp       float64\n",
       "rev_bod_id             int64\n",
       "help_prop_id           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_col = one_file[['verified_purchase', 'prod_title_comp', 'star_rating', 'rev_title_comp', 'rev_bod_id', 'help_prop_id']]\n",
    "imp_col.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_col = imp_col.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_col.iloc[:, [1,2,3,4,5]].values #only taking in the categories that will be used as a dataframe\n",
    "y = imp_col.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  5.    ,  0.    ,  1.    , -1.    ],\n",
       "       [ 0.    ,  5.    ,  0.    ,  1.    , -1.    ],\n",
       "       [ 0.    ,  5.    ,  0.    ,  1.    , -1.    ],\n",
       "       ...,\n",
       "       [ 0.2023,  5.    ,  0.    ,  1.    , -1.    ],\n",
       "       [ 0.    ,  5.    ,  0.6249,  0.    , -1.    ],\n",
       "       [ 0.    ,  5.    ,  0.    ,  1.    , -1.    ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of verified purchases (balanced dataset): 826526\n",
      "Number of unverified purchases (balanced dataset): 173363\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of verified purchases (balanced dataset):\", len(imp_col[imp_col['verified_purchase'] == 'Y']))\n",
    "print(\"Number of unverified purchases (balanced dataset):\", len(imp_col[imp_col['verified_purchase'] == 'N']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we are doing feature scaling to the training and test set of independent variables for reducing the size to smaller values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=20, p=1,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#we are using \n",
    "#5 neighborhood points are required for classifying a given point -- distance metric is using the minkonowski equation\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 20, metric = 'euclidean', p = 1)\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can evaluate our model using the confusion matrix and accuracy score by comparing the predicted and actual test values\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ac = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   775  34079]\n",
      " [  1465 163659]]\n",
      "0.8222604486493514\n"
     ]
    }
   ],
   "source": [
    "print(cm)\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Can see the model performance and add more features accordingly -- \n",
    "#would be good if the performance is greater than 85%\n",
    "\n",
    "### Test on a product review - Need to write a *function* for this for taking in the user input\n",
    "\n",
    "The features that we are looking at!\n",
    "* 'prod_title_comp', \n",
    "* 'star_rating', \n",
    "* 'rev_title_comp', \n",
    "* 'rev_bod_id', \n",
    "* 'help_prop_id'\n",
    "\n",
    "review_body = \"this is a good review\"\n",
    "product_title = \"Sony Headphones\"\n",
    "review_title = 'Love the product!'\n",
    "\n",
    "star_rating = 5\n",
    "helpful_votes = 1\n",
    "total_votes = 1\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test['review_body'] = np.array([review_body])\n",
    "test['review_title'] = np.array([review_title])\n",
    "test['product_title'] = np.array([product_title])\n",
    "test\n",
    "\n",
    "out = df_cleaning(test, 'review_body')\n",
    "out = df_cleaning(out, 'review_title')\n",
    "out = df_cleaning(out, 'product_title')\n",
    "out\n",
    "\n",
    "out['review_body'][0]\n",
    "\n",
    "def get_sentiment_proportions(review):\n",
    "    \"\"\"\n",
    "    create new dataframe with just the proportions for each review\n",
    "    four columns\n",
    "    neg_prop, pos_prop, neu_prop, compound_prop and will contain these values\n",
    "    obtained from the vator sentiment algorithm\n",
    "    \"\"\"\n",
    "    snt = analyser.polarity_scores(review)\n",
    "    #print(f\"{sentence} {str(snt)}\")\n",
    "    neg = snt['neg']\n",
    "    neu = snt['neu']\n",
    "    pos = snt['pos']\n",
    "    #compound = snt['compound']\n",
    "    return neg, neu, pos\n",
    "\n",
    "neg, neu, pos = get_sentiment_proportions(out.get(\"new_review_body\").iloc[0])\n",
    "\n",
    "product_category = convert_to_id(product_category)\n",
    "product_title = only_compound(product_title)\n",
    "rev_title = only_compound(review_title)\n",
    "\n",
    "rev_bod_id = id_for_dictionary(analyser.polarity_scores(out['new_review_body'][0]))\n",
    "help_prop_id = id_for_prop(helpful_votes / total_votes)\n",
    "prod_title_comp = only_compound(out['new_review_title'][0])\n",
    "rev_title_comp = only_compound(out['new_product_title'][0])\n",
    "\n",
    "Predicted: 'verified_purchase'\n",
    "\n",
    "User Input: 'prod_title_comp', 'product_category_convert', 'star_rating', 'helpful_votes', 'total_votes', 'neg_prop', 'neu_prop', 'pos_prop'\n",
    "- 8 fields\n",
    "\n",
    "rev_input_test = np.array([[prod_title_comp, star_rating, rev_title_comp, rev_bod_id, help_prop_id]])\n",
    "rev_input_test\n",
    "\n",
    "prediction, probabilities = knn_classifier.predict(rev_input_test), knn_classifier.predict_proba(rev_input_test)[0]\n",
    "\n",
    "prediction\n",
    "\n",
    "probabilities\n",
    "\n",
    "classifier?\n",
    "\n",
    "def interpret_prediction(review, pred, proba):\n",
    "    proba = [round(proba[0], 3), round(proba[1], 3)]\n",
    "    if prediction[0] == 'Y':\n",
    "        print(f'\"{review}\" is predicted to be a VERIFIED review, with {proba[1]*100}% probability of being VERIFIED and {proba[0]*100}% probability of being UNVERIFIED')\n",
    "    if prediction[0] == 'N':\n",
    "        print(f'\"{review}\" is predicted to be an UNVERIFIED review, with {proba[0]*100}% probability of being UNVERIFIED and {proba[1]*100}% probability of being VERIFIED')\n",
    "        \n",
    "interpret_prediction(review_test, prediction, probabilities)\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "knn_classifier\n",
    "\n",
    "name = 'knn_working_model.joblib'\n",
    "path = 'KNNModelFiles/'\n",
    "dump(knn_classifier, path+name)\n",
    "\n",
    "knn_classifier = load(path+name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
