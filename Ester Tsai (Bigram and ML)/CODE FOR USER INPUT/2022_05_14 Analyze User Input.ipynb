{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b2308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, pairwise_distances\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d296745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('year', 'old')</td>\n",
       "      <td>15450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('daughter', 'love')</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('son', 'love')</td>\n",
       "      <td>4512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bigram  count\n",
       "0       ('year', 'old')  15450\n",
       "1  ('daughter', 'love')   4759\n",
       "2       ('son', 'love')   4512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('year', 'old')</td>\n",
       "      <td>23206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('put', 'together')</td>\n",
       "      <td>5263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('daughter', 'love')</td>\n",
       "      <td>4706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bigram  count\n",
       "0       ('year', 'old')  23206\n",
       "1   ('put', 'together')   5263\n",
       "2  ('daughter', 'love')   4706"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = 'Toys'\n",
    "\n",
    "ML_model_file_path = \"C:/Users/tsaie/OneDrive/Desktop/FARS/Ester Tsai (Bigram and ML)/ML Models/\"\n",
    "\n",
    "ML_model_file_name = f'2022_05_11 rf_model {(category)}.joblib'\n",
    "rf_model = load(ML_model_file_path + ML_model_file_name) \n",
    "\n",
    "\n",
    "bigram_file_path = \"C:/Users/tsaie/OneDrive/Desktop/FARS/Ester Tsai (Bigram and ML)/Bigrams/\"\n",
    "\n",
    "gold_bigram_file_name = f'{(category)} gold_bigrams.csv'\n",
    "gold_bigram_df = pd.read_csv(bigram_file_path + gold_bigram_file_name, index_col=0)\n",
    "display(gold_bigram_df.head(3))\n",
    "\n",
    "fake_bigram_file_name = f'{(category)} fake_bigrams.csv'\n",
    "fake_bigram_df = pd.read_csv(bigram_file_path + fake_bigram_file_name, index_col=0)\n",
    "display(fake_bigram_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2169b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    # Removing emtpy cells\n",
    "    df.dropna(inplace=True)\n",
    "    df['review_cleaned'] = df['review_body'].copy()\n",
    "    \n",
    "    # Removing Unicode Chars (URL)\n",
    "    df['review_cleaned'] = df['review_cleaned'].apply(\n",
    "        lambda rev: re.sub(r\"(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", rev))\n",
    "        \n",
    "    # Replace HTML keywords with blank space (\"&quot;\", \"br\", \"&#34\")\n",
    "    remove_dict = {\"<br /><br />\": \" \", \"<br />\": \" \", \"br \": \"\", \"&quot;\": \" \", \"&#34\": \" \",\n",
    "                   \"<BR>\": \" \", \"_\": \"\"}\n",
    "    for key, val in remove_dict.items():\n",
    "        df['review_cleaned'] = df['review_cleaned'].apply(\n",
    "            lambda x: x.replace(key, val))\n",
    "        \n",
    "    print(\"\\n######## Remove URL and HTML Keywords Complete ########\")\n",
    "    \n",
    "    # Remove Punctuations and numbers\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df['review_cleaned'] = df['review_cleaned'].apply(\n",
    "        lambda x: ' '.join([word for word in tokenizer.tokenize(x)]))\n",
    "    \n",
    "    remove_dict = {\"0\": \"\", \"1\": \"\", \"2\": \"\", \"3\": \"\", \"4\": \"\", \"5\": \"\", \"6\": \"\", \"7\": \"\", \"8\": \"\", \"9\": \"\",\n",
    "                   \"(\": \"\", \")\":\"\"}\n",
    "    for key, val in remove_dict.items():\n",
    "        df['review_cleaned'] = df['review_cleaned'].apply(\n",
    "            lambda x: x.replace(key, val))\n",
    "    \n",
    "    print(\"\\n######## Remove Punctuation and Numbers Complete ########\")\n",
    "    \n",
    "    # Lowercase Words\n",
    "    df['review_cleaned'] = df['review_cleaned'].str.lower()\n",
    "    \n",
    "    print(\"\\n######## Lowercase Complete ########\")\n",
    "\n",
    "    # Remove Stop Words.\n",
    "    stop = stopwords.words('english')\n",
    "      \n",
    "    df['review_cleaned'] = df['review_cleaned'].apply(\n",
    "        lambda x: ' '.join([word for word in x.split() if word.strip() not in stop]))\n",
    "    \n",
    "    print(\"\\n######## Remove Stop Words Complete ########\")\n",
    "    \n",
    "    # Lemmatization using .lemma_\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    df['review_cleaned'] = df['review_cleaned'].apply(\n",
    "        lambda x: ' '.join([token.lemma_ for token in nlp(x)]))\n",
    "    \n",
    "    print(\"\\n######## Data Cleaning Complete ########\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "from itertools import chain\n",
    "\n",
    "def find_ngrams(input_list, n):\n",
    "    return list(zip(*[input_list[i:] for i in range(n)]))\n",
    "\n",
    "def add_bigram_column(df):\n",
    "    copy = df.copy()\n",
    "    copy['bigrams'] = copy['review_cleaned'].map(lambda x: find_ngrams(x.split(), 2))\n",
    "    return copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_bigram_count(bigrams, bigram_dict):\n",
    "    if len(bigrams) == 0:\n",
    "        return 0\n",
    "    \n",
    "    count = 0\n",
    "    for bigram in bigrams:\n",
    "        if bigram in bigram_dict.keys():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def get_count_percent(bigrams, bigram_dict):\n",
    "    if len(bigrams) == 0:\n",
    "        return 0\n",
    "    \n",
    "    count = get_bigram_count(bigrams, bigram_dict)\n",
    "    return count / len(bigrams)\n",
    "\n",
    "def get_averge_top_score(bigrams, bigram_dict, topN=5):\n",
    "    if len(bigrams) == 0:\n",
    "        return 0\n",
    "    \n",
    "    scores = np.array([])\n",
    "    for bigram in bigrams:\n",
    "        if bigram in bigram_dict.keys():\n",
    "            scores = np.append(scores, bigram_dict[bigram])\n",
    "    \n",
    "    if len(bigrams) <= topN:\n",
    "        return scores.mean()\n",
    "    \n",
    "    sort_descending = -np.sort(-scores)[:topN]\n",
    "    avg_top_score = sort_descending.mean()\n",
    "    return avg_top_score\n",
    "\n",
    "def get_normalized_score(bigrams, bigram_dict):\n",
    "    if len(bigrams) == 0:\n",
    "        return 0\n",
    "    \n",
    "    score = 0\n",
    "    for bigram in bigrams:\n",
    "        if bigram in bigram_dict.keys():\n",
    "            score += bigram_dict[bigram]\n",
    "    return score / len(bigrams)\n",
    "\n",
    "def get_unique_percent(bigrams, bigram_dict, the_other_bigram_dict, unique_threshold=0):\n",
    "    # Count the number of bigrams in a review that appear in bigram_dict but not the_other_bigram_dict. \n",
    "    # Can adjust unique_threshold so you can count also the bigrams that appear in ...\n",
    "    # ...the_other_bigram_dict fewer than unique_threshold times\n",
    "    \n",
    "    if len(bigrams) == 0:\n",
    "        return 0\n",
    "    \n",
    "    count = get_bigram_count(bigrams, bigram_dict)\n",
    "    for bigram in bigrams:\n",
    "        if bigram in the_other_bigram_dict.keys():\n",
    "            if the_other_bigram_dict[bigram] > unique_threshold:\n",
    "                count -= 1\n",
    "    return count / len(bigrams)\n",
    "\n",
    "def has_fake_keywords(bigrams):\n",
    "    fake_keywords = ['honest', 'unbiased', 'unbias', 'biased', 'bias', 'neutral', 'impartial', 'truthful', \n",
    "                     'discount', 'free', 'promotion', 'promote', 'complimentary', 'test', 'influence', 'influencer',\n",
    "                     'independent']\n",
    "    fake_tuples = [('receive', 'product'), ('product', 'receive'), ('provide', 'review'), \n",
    "                   ('product', 'exchange'), ('exchange', 'review'), ('review', 'opinion'),\n",
    "                   ('sample', 'provide'), ('provide', 'sample'), ('sample', 'review'), ('review', 'sample'), \n",
    "                   ('sample', 'product'), ('supply', 'sample'), ('receive', 'sample'), ('sample', 'receive')] \n",
    "    \n",
    "    for kw in fake_tuples:\n",
    "        if kw in bigrams:\n",
    "            return True\n",
    "            \n",
    "    for bigram in bigrams:\n",
    "        for kw in fake_keywords:\n",
    "            if kw in bigram:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_gold_fake_features(df):\n",
    "    \n",
    "    for gold_or_fake in ['gold', 'fake']:\n",
    "\n",
    "        exec(f\"df['{gold_or_fake}%'] = df['bigrams'].apply(\\\n",
    "            lambda x: get_count_percent(x, {gold_or_fake}_bigram_dict_filtered))\")\n",
    "        \n",
    "        exec(f\"df['{gold_or_fake}_unique%'] = df['bigrams'].apply(\\\n",
    "            lambda x: get_unique_percent(x, {gold_or_fake}_bigram_dict, {gold_or_fake}_bigram_dict, 3))\")\n",
    "\n",
    "        exec(f\"df['{gold_or_fake}_score'] = df['bigrams'].apply(\\\n",
    "            lambda x: get_normalized_score(x, {gold_or_fake}_bigram_dict))\")\n",
    "        \n",
    "        exec(f\"df['{gold_or_fake}_top_score'] = df['bigrams'].apply(\\\n",
    "            lambda x: get_averge_top_score(x, {gold_or_fake}_bigram_dict, 1))\")\n",
    "        \n",
    "        exec(f\"df['{gold_or_fake}_top_avg_score'] = df['bigrams'].apply(\\\n",
    "            lambda x: get_averge_top_score(x, {gold_or_fake}_bigram_dict, 5))\")\n",
    "\n",
    "    df['has_fake_keywords'] = df['bigrams'].apply(lambda x: has_fake_keywords(x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gold_bigram_df_to_vars(gold_bigram_df):\n",
    "    global gold_bigrams, gold_bigram_dict, gold_bigram_dict_filtered\n",
    "    gold_bigrams = gold_bigram_df['bigram'].to_list()\n",
    "    str_to_tuple = lambda x: (x.split(\"'\")[1], x.split(\"'\")[3])\n",
    "    gold_bigrams = list(map(str_to_tuple, gold_bigrams))\n",
    "    gold_bigram_dict = {gold_bigrams[i]: gold_bigram_df['count'].iloc[i] for i in range(len(gold_bigrams))}\n",
    "    gold_bigram_dict_filtered = dict((k, v) for k, v in gold_bigram_dict.items() if v >= 2)\n",
    "    \n",
    "def fake_bigram_df_to_vars(fake_bigram_df):\n",
    "    global fake_bigrams, fake_bigram_dict, fake_bigram_dict_filtered\n",
    "    fake_bigrams = fake_bigram_df['bigram'].to_list()\n",
    "    str_to_tuple = lambda x: (x.split(\"'\")[1], x.split(\"'\")[3])\n",
    "    fake_bigrams = list(map(str_to_tuple, fake_bigrams))\n",
    "    fake_bigram_dict = {fake_bigrams[i]: fake_bigram_df['count'].iloc[i] for i in range(len(fake_bigrams))}\n",
    "    fake_bigram_dict_filtered = dict((k, v) for k, v in fake_bigram_dict.items() if v >= 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def clean_review_and_add_features(review, gold_bigram_df, fake_bigram_df):\n",
    "    # Create dataframe for the singular review\n",
    "    df = pd.DataFrame(data={'review_body': review}, index=[0])\n",
    "    \n",
    "    # Generate gold/{gold_or_fake} bigrams in order to score the user input\n",
    "    gold_bigram_df_to_vars(gold_bigram_df)\n",
    "    fake_bigram_df_to_vars(fake_bigram_df)\n",
    "    \n",
    "    # Clean the user input\n",
    "    df = data_cleaning(df) \n",
    "#     df = add_bigram_column(df)\n",
    "    df['bigrams'] = df['review_cleaned'].map(lambda x: find_ngrams(x.split(), 2))\n",
    "    \n",
    "    # Add features\n",
    "    df['bigram_count'] = df['bigrams'].apply(lambda x: len(x))\n",
    "    \n",
    "    df = add_gold_fake_features(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae0f8c",
   "metadata": {},
   "source": [
    "## Try changing the review and see what the RandomForest model predicts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "238e1e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######## Remove URL and HTML Keywords Complete ########\n",
      "\n",
      "######## Remove Punctuation and Numbers Complete ########\n",
      "\n",
      "######## Lowercase Complete ########\n",
      "\n",
      "######## Remove Stop Words Complete ########\n",
      "\n",
      "######## Data Cleaning Complete ########\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_cleaned</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>bigram_count</th>\n",
       "      <th>gold%</th>\n",
       "      <th>gold_unique%</th>\n",
       "      <th>gold_score</th>\n",
       "      <th>gold_top_score</th>\n",
       "      <th>gold_top_avg_score</th>\n",
       "      <th>fake%</th>\n",
       "      <th>fake_unique%</th>\n",
       "      <th>fake_score</th>\n",
       "      <th>fake_top_score</th>\n",
       "      <th>fake_top_avg_score</th>\n",
       "      <th>has_fake_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turbo charger, small and portable and fits per...</td>\n",
       "      <td>turbo charger small portable fit perfectly poc...</td>\n",
       "      <td>[(turbo, charger), (charger, small), (small, p...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>32.428571</td>\n",
       "      <td>426.0</td>\n",
       "      <td>88.8</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>102.642857</td>\n",
       "      <td>779.0</td>\n",
       "      <td>284.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  \\\n",
       "0  Turbo charger, small and portable and fits per...   \n",
       "\n",
       "                                      review_cleaned  \\\n",
       "0  turbo charger small portable fit perfectly poc...   \n",
       "\n",
       "                                             bigrams  bigram_count     gold%  \\\n",
       "0  [(turbo, charger), (charger, small), (small, p...            14  0.571429   \n",
       "\n",
       "   gold_unique%  gold_score  gold_top_score  gold_top_avg_score     fake%  \\\n",
       "0      0.642857   32.428571           426.0                88.8  0.642857   \n",
       "\n",
       "   fake_unique%  fake_score  fake_top_score  fake_top_avg_score  \\\n",
       "0      0.285714  102.642857           779.0               284.6   \n",
       "\n",
       "   has_fake_keywords  \n",
       "0               True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 seconds\n",
      "\n",
      "REVIEW: \"Turbo charger, small and portable and fits perfectly in your pocket! A nice boost over regular chargers. I received this in exchange for an unbiased review.\" \n",
      "\n",
      "PREDICTION: UNVERIFIED (69.1%) | VERIFIED (30.9%)\n"
     ]
    }
   ],
   "source": [
    "review = \"Turbo charger, small and portable and fits perfectly in your pocket! A nice boost over regular chargers. I received this in exchange for an unbiased review.\"\n",
    "#9994 \"This is a thick high quality cable, my picture is crystal clear and this is just the right length for my needs, I received this in exchange for my honest review.\"\n",
    "#112 Small,lightweight,fits on my desk. Does not come with batteries,I already had some.I received a discount for this review.\n",
    "#59356 Turbo charger, small and portable and fits perfectly in your pocket! A nice boost over regular chargers. I received this in exchange for an unbiased review.\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Clean the user input and create a dataframe for it\n",
    "user_input_processed_df = clean_review_and_add_features(review, gold_bigram_df, fake_bigram_df)\n",
    "display(user_input_processed_df)\n",
    "\n",
    "def prepare_df_for_prediction(processed_df):\n",
    "    features = ['bigram_count', \n",
    "            'fake%', 'fake_unique%', 'fake_score', 'fake_top_avg_score', 'fake_top_score',\n",
    "            'gold%', 'gold_unique%', 'gold_score', 'gold_top_avg_score', 'gold_top_score',\n",
    "            'has_fake_keywords']\n",
    "    return processed_df[features]\n",
    "\n",
    "df_for_prediction = prepare_df_for_prediction(user_input_processed_df)\n",
    "\n",
    "prediction, probabilities = rf_model.predict(df_for_prediction), rf_model.predict_proba(df_for_prediction)[0]\n",
    "\n",
    "def interpret_prediction(review, pred, proba):\n",
    "    prob_unverified, prob_verified = round(proba[0] * 100, 1), round(proba[1] * 100, 1)\n",
    "    print(f'\\nREVIEW: \"{review}\" \\n')\n",
    "    if pred == 1:\n",
    "        print(f'PREDICTION: VERIFIED ({prob_verified}%) | UNVERIFIED ({prob_unverified}%)')\n",
    "    if pred == 0:\n",
    "        print(f'PREDICTION: UNVERIFIED ({prob_unverified}%) | VERIFIED ({prob_verified}%)')\n",
    "\n",
    "end_time = time()\n",
    "print(round(end_time - start_time), \"seconds\")\n",
    "\n",
    "interpret_prediction(review, prediction[0], probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc047bfc",
   "metadata": {},
   "source": [
    "# Gold & Fake Reviews from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db6347",
   "metadata": {},
   "source": [
    "## Electronics\n",
    "\n",
    "### Gold:\n",
    "\n",
    "\n",
    "### Fake:\n",
    "\n",
    "Turbo charger, small and portable and fits perfectly in your pocket! A nice boost over regular chargers. I received this in exchange for an unbiased review.\n",
    "\n",
    "This is a thick high quality cable, my picture is crystal clear and this is just the right length for my needs, I received this in exchange for my honest review.\n",
    "\n",
    "Small, lightweight, fits on my desk. Does not come with batteries, I already had some. I received a discount for this review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f53794",
   "metadata": {},
   "source": [
    "## Beauty\n",
    "\n",
    "### Gold:\n",
    "\n",
    "\n",
    "### Fake:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2205f02d",
   "metadata": {},
   "source": [
    "## Toys\n",
    "\n",
    "### Gold:\n",
    "\n",
    "\n",
    "### Fake:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febde26b",
   "metadata": {},
   "source": [
    "## Office Products\n",
    "\n",
    "### Gold:\n",
    "\n",
    "\n",
    "### Fake:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743b292",
   "metadata": {},
   "source": [
    "## Apparel\n",
    "\n",
    "### Gold:\n",
    "\n",
    "\n",
    "### Fake:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a815257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
